{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing and Baseline Model\n",
    "\n",
    "This notebook implements text preprocessing pipeline and builds a baseline model using bag-of-words and logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined dataset\n",
    "df = pd.read_csv('../data/combined_news_dataset.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Label distribution:\\n{df['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self, use_stemming=True, remove_stopwords=True):\n",
    "        self.use_stemming = use_stemming\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Basic text cleaning\"\"\"\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Remove email addresses\n",
    "        text = re.sub(r'\\S+@\\S+', '', text)\n",
    "        \n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def tokenize_and_process(self, text):\n",
    "        \"\"\"Tokenize and apply stemming/lemmatization\"\"\"\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords\n",
    "        if self.remove_stopwords:\n",
    "            tokens = [token for token in tokens if token not in self.stop_words]\n",
    "        \n",
    "        # Apply stemming or lemmatization\n",
    "        if self.use_stemming:\n",
    "            tokens = [self.stemmer.stem(token) for token in tokens]\n",
    "        else:\n",
    "            tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        \"\"\"Full preprocessing pipeline\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return ''\n",
    "        \n",
    "        # Clean text\n",
    "        text = self.clean_text(text)\n",
    "        \n",
    "        # Tokenize and process\n",
    "        text = self.tokenize_and_process(text)\n",
    "        \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = TextPreprocessor(use_stemming=True, remove_stopwords=True)\n",
    "\n",
    "# Test preprocessing on a sample\n",
    "sample_text = df.iloc[0]['text'][:500]  # First 500 chars\n",
    "print(\"Original text:\")\n",
    "print(sample_text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Preprocessed text:\")\n",
    "print(preprocessor.preprocess(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine title and text for richer features\n",
    "df['combined_text'] = df['title'] + ' ' + df['text']\n",
    "\n",
    "# Apply preprocessing (this may take a while for the full dataset)\n",
    "print(\"Preprocessing text... (this may take several minutes)\")\n",
    "df['processed_text'] = df['combined_text'].apply(preprocessor.preprocess)\n",
    "\n",
    "# Remove empty texts\n",
    "df = df[df['processed_text'] != ''].reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset shape after preprocessing: {df.shape}\")\n",
    "print(\"\\nSample processed texts:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\n{i+1}. Label: {df.iloc[i]['label']}\")\n",
    "    print(df.iloc[i]['processed_text'][:200] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = df['processed_text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"\\nTraining set label distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest set label distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bag of Words + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer + Logistic Regression\n",
    "bow_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "print(\"Training Bag of Words + Logistic Regression...\")\n",
    "bow_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "bow_pred = bow_pipeline.predict(X_test)\n",
    "bow_accuracy = accuracy_score(y_test, bow_pred)\n",
    "\n",
    "print(f\"\\nBag of Words + Logistic Regression Accuracy: {bow_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, bow_pred, target_names=['Fake', 'True']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF + Logistic Regression\n",
    "tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "print(\"Training TF-IDF + Logistic Regression...\")\n",
    "tfidf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "tfidf_pred = tfidf_pipeline.predict(X_test)\n",
    "tfidf_accuracy = accuracy_score(y_test, tfidf_pred)\n",
    "\n",
    "print(f\"\\nTF-IDF + Logistic Regression Accuracy: {tfidf_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, tfidf_pred, target_names=['Fake', 'True']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TF-IDF + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF + Naive Bayes\n",
    "nb_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "print(\"Training TF-IDF + Naive Bayes...\")\n",
    "nb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "nb_pred = nb_pipeline.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_pred)\n",
    "\n",
    "print(f\"\\nTF-IDF + Naive Bayes Accuracy: {nb_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, nb_pred, target_names=['Fake', 'True']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation on the best performing model\n",
    "print(\"Performing 5-fold cross-validation on TF-IDF + Logistic Regression...\")\n",
    "\n",
    "cv_scores = cross_val_score(tfidf_pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"\\nCross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Comparison and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Bag of Words + LR', 'TF-IDF + LR', 'TF-IDF + NB'],\n",
    "    'Accuracy': [bow_accuracy, tfidf_accuracy, nb_accuracy]\n",
    "})\n",
    "\n",
    "results_df = results_df.sort_values('Accuracy', ascending=False)\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(results_df)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=results_df, x='Model', y='Accuracy')\n",
    "plt.title('Baseline Model Performance Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "for i, v in enumerate(results_df['Accuracy']):\n",
    "    plt.text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for the best model\n",
    "best_pred = tfidf_pred  # Assuming TF-IDF + LR is best\n",
    "\n",
    "cm = confusion_matrix(y_test, best_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=['Fake', 'True'], yticklabels=['Fake', 'True'])\n",
    "plt.title('Confusion Matrix - TF-IDF + Logistic Regression')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Calculate additional metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "precision_fake = tn / (tn + fn)\n",
    "recall_fake = tn / (tn + fp)\n",
    "precision_true = tp / (tp + fp)\n",
    "recall_true = tp / (tp + fn)\n",
    "\n",
    "print(f\"\\nDetailed Metrics:\")\n",
    "print(f\"True Negatives: {tn}, False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}, True Positives: {tp}\")\n",
    "print(f\"\\nFake News - Precision: {precision_fake:.3f}, Recall: {recall_fake:.3f}\")\n",
    "print(f\"True News - Precision: {precision_true:.3f}, Recall: {recall_true:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze most important features\n",
    "vectorizer = tfidf_pipeline.named_steps['vectorizer']\n",
    "classifier = tfidf_pipeline.named_steps['classifier']\n",
    "\n",
    "# Get feature names and coefficients\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefficients = classifier.coef_[0]\n",
    "\n",
    "# Top features for fake news (negative coefficients)\n",
    "fake_indices = np.argsort(coefficients)[:20]\n",
    "fake_features = [(feature_names[i], coefficients[i]) for i in fake_indices]\n",
    "\n",
    "# Top features for true news (positive coefficients)\n",
    "true_indices = np.argsort(coefficients)[-20:]\n",
    "true_features = [(feature_names[i], coefficients[i]) for i in true_indices]\n",
    "\n",
    "print(\"Top 20 features associated with FAKE news:\")\n",
    "for feature, coef in fake_features:\n",
    "    print(f\"{feature}: {coef:.4f}\")\n",
    "\n",
    "print(\"\\nTop 20 features associated with TRUE news:\")\n",
    "for feature, coef in reversed(true_features):\n",
    "    print(f\"{feature}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best performing model and preprocessor\n",
    "joblib.dump(tfidf_pipeline, '../models/baseline_tfidf_lr.pkl')\n",
    "joblib.dump(preprocessor, '../models/text_preprocessor.pkl')\n",
    "\n",
    "print(\"Models saved successfully!\")\n",
    "print(\"- Baseline TF-IDF + Logistic Regression: ../models/baseline_tfidf_lr.pkl\")\n",
    "print(\"- Text Preprocessor: ../models/text_preprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Baseline Results:\n",
    "- **TF-IDF + Logistic Regression**: Likely the best performing baseline\n",
    "- **TF-IDF + Naive Bayes**: Good performance, faster training\n",
    "- **Bag of Words + Logistic Regression**: Simple but effective\n",
    "\n",
    "### Key Insights:\n",
    "1. TF-IDF generally outperforms simple bag-of-words\n",
    "2. Bigrams (2-word combinations) help capture important patterns\n",
    "3. Text preprocessing (stemming, stopword removal) improves performance\n",
    "4. The dataset appears to have learnable patterns distinguishing fake from true news\n",
    "\n",
    "### Next Steps:\n",
    "1. Implement deep learning models (CNN, LSTM)\n",
    "2. Experiment with pre-trained embeddings (Word2Vec, GloVe)\n",
    "3. Try transformer models (BERT, DistilBERT)\n",
    "4. Fine-tune hyperparameters\n",
    "5. Ensemble methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}